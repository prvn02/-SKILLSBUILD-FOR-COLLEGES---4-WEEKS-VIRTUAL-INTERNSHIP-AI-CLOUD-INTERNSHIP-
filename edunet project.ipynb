{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0335a10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  LIMIT_BAL SEX   EDUCATION MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
      "0   1      20000   F  University  Married   24      2      2     -1     -1   \n",
      "1   2     120000   F  University   Single   26     -1      2      0      0   \n",
      "2   3      90000   F  University   Single   34      0      0      0      0   \n",
      "3   4      50000   F  University  Married   37      0      0      0      0   \n",
      "4   5      50000   M  University  Married   57     -1      0     -1      0   \n",
      "\n",
      "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
      "0  ...          0          0          0         0       689         0   \n",
      "1  ...       3272       3455       3261         0      1000      1000   \n",
      "2  ...      14331      14948      15549      1518      1500      1000   \n",
      "3  ...      28314      28959      29547      2000      2019      1200   \n",
      "4  ...      20940      19146      19131      2000     36681     10000   \n",
      "\n",
      "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default   \n",
      "0         0         0         0         Y  \n",
      "1      1000         0      2000         Y  \n",
      "2      1000      1000      5000         N  \n",
      "3      1100      1069      1000         N  \n",
      "4      9000       689       679         N  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 25 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   ID         30000 non-null  int64 \n",
      " 1   LIMIT_BAL  30000 non-null  int64 \n",
      " 2   SEX        30000 non-null  object\n",
      " 3   EDUCATION  30000 non-null  object\n",
      " 4   MARRIAGE   30000 non-null  object\n",
      " 5   AGE        30000 non-null  int64 \n",
      " 6   PAY_0      30000 non-null  int64 \n",
      " 7   PAY_2      30000 non-null  int64 \n",
      " 8   PAY_3      30000 non-null  int64 \n",
      " 9   PAY_4      30000 non-null  int64 \n",
      " 10  PAY_5      30000 non-null  int64 \n",
      " 11  PAY_6      30000 non-null  int64 \n",
      " 12  BILL_AMT1  30000 non-null  int64 \n",
      " 13  BILL_AMT2  30000 non-null  int64 \n",
      " 14  BILL_AMT3  30000 non-null  int64 \n",
      " 15  BILL_AMT4  30000 non-null  int64 \n",
      " 16  BILL_AMT5  30000 non-null  int64 \n",
      " 17  BILL_AMT6  30000 non-null  int64 \n",
      " 18  PAY_AMT1   30000 non-null  int64 \n",
      " 19  PAY_AMT2   30000 non-null  int64 \n",
      " 20  PAY_AMT3   30000 non-null  int64 \n",
      " 21  PAY_AMT4   30000 non-null  int64 \n",
      " 22  PAY_AMT5   30000 non-null  int64 \n",
      " 23  PAY_AMT6   30000 non-null  int64 \n",
      " 24  default    30000 non-null  object\n",
      "dtypes: int64(21), object(4)\n",
      "memory usage: 5.7+ MB\n",
      "None\n",
      "Index(['ID', 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0',\n",
      "       'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',\n",
      "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
      "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'default '],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\Dell\\\\Downloads\\\\Credit Card Defaulter Prediction.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head())\n",
    "\n",
    "# Display information about the dataset, such as the number of records, columns, and data types\n",
    "print(data.info())\n",
    "\n",
    "# Display column names to verify the presence of the 'default' column\n",
    "print(data.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e0b85a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.67235902 -0.80815856  0.99286117  0.93348572 -1.2446578   0.01479575\n",
      "   0.10969398  0.14111968  0.18869959  0.23405483  0.25057055  0.32966974\n",
      "   0.40097887  0.45570705  0.47944982 -0.00836705  0.01169789 -0.12689188\n",
      "  -0.03953698 -0.17356677 -0.22465419 -0.21600791 -0.24524018]\n",
      " [-1.05776818  1.23738094  0.99286117  0.93348572 -0.81152149  0.01479575\n",
      "   0.10969398  0.14111968  0.18869959  0.23405483  0.25057055 -0.29544512\n",
      "  -0.27364945 -0.25413172 -0.27718187 -0.29932295 -0.65389759 -0.03891505\n",
      "  -0.19425036 -0.2415957  -0.24078483 -0.30852284 -0.29553162]\n",
      " [ 0.0984593  -0.80815856  1.70992258 -1.07716336  0.92102376  0.01479575\n",
      "   0.10969398 -0.69804592 -0.6674044  -0.64861581 -0.61720624 -0.40887943\n",
      "  -0.68969797 -0.66278784 -0.67137143 -0.54868545 -0.47947335 -0.33193699\n",
      "  -0.2104753  -0.28824568  0.12267581  0.35348711 -0.28510675]\n",
      " [-0.82652269  1.23738094 -1.15832309  0.93348572 -1.13637372  0.01479575\n",
      "   0.10969398  0.14111968  0.18869959  0.23405483  0.25057055  0.10778755\n",
      "   0.06091521 -0.11873596 -0.05267097 -0.00876287  0.00635045 -0.21381508\n",
      "  -0.16723626 -0.17861001 -0.20735823 -0.18687691 -0.18097254]\n",
      " [-0.28694986 -0.80815856  0.99286117  0.93348572 -1.13637372  0.01479575\n",
      "   0.10969398  0.14111968  0.18869959  0.23405483  0.25057055  0.82643189\n",
      "   0.89440816  0.98142318  1.16765438  1.33098333  1.43622436 -0.09194699\n",
      "  -0.07252219 -0.01415651  0.00730803  0.01159803  0.31735947]]\n",
      "21753    0\n",
      "251      0\n",
      "22941    0\n",
      "618      0\n",
      "17090    0\n",
      "Name: default , dtype: int32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\Dell\\\\Downloads\\\\Credit Card Defaulter Prediction.csv\")\n",
    "\n",
    "# Step 2: Data Preprocessing\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "data['SEX'] = label_encoder.fit_transform(data['SEX'])\n",
    "data['EDUCATION'] = label_encoder.fit_transform(data['EDUCATION'].astype(str))  # Convert to string to handle potential mixed data types\n",
    "data['MARRIAGE'] = label_encoder.fit_transform(data['MARRIAGE'].astype(str))  # Convert to string to handle potential mixed data types\n",
    "data['default '] = label_encoder.fit_transform(data['default '])\n",
    "\n",
    "# Split features and target variable\n",
    "X = data.drop(columns=['ID', 'default '])  # Features\n",
    "y = data['default ']  # Target variable\n",
    "\n",
    "# Split the dataset into the training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Display the first few rows of preprocessed data\n",
    "print(X_train[:5])  # Displaying first 5 rows of training data after preprocessing\n",
    "print(y_train[:5])  # Displaying first 5 rows of training target variable after preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38e987df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(random_state=42)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Step 3: Model Training\n",
    "# Using Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Print the trained model\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14d69c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8153333333333334\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      4687\n",
      "           1       0.64      0.36      0.46      1313\n",
      "\n",
      "    accuracy                           0.82      6000\n",
      "   macro avg       0.74      0.65      0.68      6000\n",
      "weighted avg       0.80      0.82      0.80      6000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4417  270]\n",
      " [ 838  475]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Step 4: Model Evaluation\n",
    "# Making predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Generating classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Generating confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22436f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully as random_forest_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Step 5: Save the trained model\n",
    "# Define the file path to save the model\n",
    "model_filename = \"random_forest_model.pkl\"\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(model, model_filename)\n",
    "\n",
    "print(\"Model saved successfully as\", model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a8ac5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
